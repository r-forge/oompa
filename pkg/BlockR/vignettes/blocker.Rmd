---
title: "BlockR: Statistical Interpretation of Two-way Clustered Heatmaps"
author:
  - "Kevin R. Coombes, Medical College of Georgia at Augusta University"
  - "Steven Kornblau, University of Texas M.D. Anderson Cancer Center"
data: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{BlockR: Statistical Interpretation of Two-way Clustered Heatmaps}
  %\VignetteKeywords{OOMPA,heatmap,linear regression,tiling, blocks}
  %\VignetteDepends{BlockR}
  %\VignettePackage{BlockR}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r opts, echo=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=6)
options(width=96)
.format <- knitr::opts_knit$get("rmarkdown.pandoc.to")
.tag <- function(N, cap ) ifelse(.format == "html",
                                 paste("Figure", N, ":",  cap),
                                 cap)
```

# Introduction
For more than 20 years, since the earliest days of microarray studies,
two-way clustered heatmaps have been an important tool for
visualization of omics data. [Weinstein97, Eisen98] Surprisingly, in
all that time, the interpretation of such heatmaps has relied almost
excluively on informal "eyeball" tests looking for rectangular regions
of features and samples with similar levels of expression. A study in
2017, which focused on assessing alternative visual representations of
the data, conducted surveys and interviews and found that
"[p]ractitioners most frequently looked for blocks of cells or bands
of rows and/or columns in the heatmap". [Engle2017] At present, we do
not know of any studies that attempted to assign statistical
significance to these color blocks or bands.

We find this state of affairs surprising, in part, because many
statistical methods have been developed to assess the row and column
dendrograms that appear on the borders of the clustered
heatmaps. These methods are primarily directed toward estimating the
number of clusters present in the data. (For a survey of such methods,
see [charrad14].)

In this paper, we propose a statstical method to estimate the number
of rectangular "blocks" or "tiles" present in the heatmap. In effect,
our method is equivalent to simultaneously estimating the number of
row-clusters and the number of column-clusters in the data. Our
approach is based on using linear regression to estimate the mean
expression in each block after cutting the row and column dendrograms
to define clusters. It is inspired, in part, by the common use of
either the Akaike Inforation Criterion (AIC) or the Bayes Information
Criterion (BIC) to select the optimal number of parameters in a linear
model by imposing a penalty based on the number of parameters.

Our main innovation in this application comes from the realization
that not all of the data present in a typical clustered heatmap is
independent. Certainly, data arising from different patient samples is
statistically independent. But data arising from different genes,
proteins, or other omics features is highly unlikely to be
independent. If we were to treat it as independent, then the AIC or
BIC penalties arising from the number of parameters would be
inadequate to overcome the log likelihood estimates. In that
situation, we wold tend to choose unrealistically large estimates of
the number of clusters and blocks or tiles present in the
data. Instead, we introduce methods to estimate the empirical number
of degrees of freedom that we can use instead of the full size of the
data matrix used to construct the heatmap.

```{r setOptions, echo=FALSE}
set.seed(625996)
options(width=88)
options(SweaveHooks = list(fig = function() par(bg='white')))
```

# Executive Summary
## Introduction
### Background
\textbf{This report is prepared for Dr. Steven Kornblau}. This is a
reversed phase protein array (RPPA) dataset that is generated by using
the samples from patients with Acute Lymphoblastic Leukemia (ALL) and
Acute myeloid leukemia (AML).  The RPPA data has been normalized
properly and clinical data has been cleaned and updated.
\newline
### Objectives
The objectives of this analysis is to perform clustering analysis
using genes related to \Sexpr{pathway}.

## Methods
### Data
The full dataset contains 719 AML samples from 511 AML patients; these
have been combijned to adjust for the effects of fresh-vs-frozen or
diagnosis-vs-relapse samples.  We have mneasurements on a total of 203
different antibodies, along with data on 81 clinical variables
including demographics, cytogenetics, treatment, disease information,
and flow cytometry data. The training and testing set of AML samples
were re-defined on June 22, 2010. The newly defined training set is
used for survival analysis.

### Statistical Methods


## Results

# Library Packages
Our analysis uses the following R packages.
```{r libs}
library(colorspace)
library(RColorBrewer)
library(xtable)
library(gplots)
library(mclust)
library(ClassDiscovery)
library(ClassComparison)
library(BlockR)
```

We select ``clade'' colors from this list.
```{r clade.cols}
cols <- c("blue", "red", "green", "purple", "gold", "cyan",
          "magenta", "blueviolet", "brown", "darkcyan", 
          "darkgoldenrod", "forestgreen", "gainsboro", 
          "ghostwhite", "gold", "grey100", "honeydew", 
          "ivory4", "khaki", "pink", "orange")
```

Now we load the data.
```{r loaddata}
data("AMLRPPA")
dim(AMLRPPA)
```

## {Random noise matrices}
Here we apply the ``blocker'' method to random matrices of the same
size as the one we are using.
```{r rando}
f <- "randoms.rda"
if (file.exists(f)) {
  load(f)
} else {
  nruns <- 200
  cat("Simulating\n", file=stderr())
  temp <- list()
  for (i in 1:nruns) {
    cat(i, "\n", file=stderr())
    dataset <- matrix(rnorm(prod(dim(AMLRPPA))), ncol=ncol(AMLRPPA))
    temp[[i]] <- blocker(dataset)
  }
  randoms <- array(NA, dim=c(nrow(temp[[1]]), ncol(temp[[1]]), nruns))
  for (i in 1:nruns) {
    randoms[,,i] <- as.matrix(temp[[i]])
  }
  rm(nruns, i, temp, dataset)
  save(randoms, file=f)
}
rm(f)
```

Now we compute the mean values obtained over multiple random matrices.
Plots of the mean squared residuals (MSR) as a function of the number
of protein groups and sample groups show that the MSR decreases in a
regular pattern as the number of groups increases (\fref{ranmean}).
```{r ranmean}
ranMean <- apply(randoms, 1:2, mean)
ranPivot <- pivot(ranMean)
colnames(ranMean) <- c("ProteinGroups", "SampleGroups", "MeanMSE")
ranMean <- as.data.frame(ranMean)
```

```{r fig=TRUE,echo=FALSE}
attach(ranMean)
interaction.plot(SampleGroups, ProteinGroups, MeanMSE, type='b')
detach()
```
\caption{Mean squared residuals in \textbf{random} matrices as a
  function of the numbers of protein groups and sample groups.}
\label{ranmean}
\end{figure}
\clearpage
## {Scrambled matrices}
Here we apply the ``blocker'' method to scrambled versions of our
data.  We have scrambled the data within each column (protein), which
preserves the distribution of the protein data but breaks all of the
correlations. 
```{r scrambo}
f <- "scrambled.rda"
if (file.exists(f)) {
  load(f)
} else {
  cat("Scrambling\n", file=stderr())
  temp<- list()
  for (i in 1:100) {
    cat(i, "\n", file=stderr())    
    dataset <- matrix(NA, ncol=ncol(AMLRPPA), nrow=nrow(AMLRPPA))
    for (j in 1:ncol(AMLRPPA)) {
      dataset[,j] <- sample(AMLRPPA[,j])
    }
    temp[[i]] <- blocker(dataset)
  }
  scrambled <- array(NA, dim=c(nrow(temp[[1]]), ncol(temp[[1]]), 100))
  for (i in 1:100) {
    scrambled[,,i] <- as.matrix(temp[[i]])
  }
  rm(i, j, temp, dataset)
  save(scrambled, file=f)
}
rm(f)
```

Now we compute the mean values obtained over multiple scrambled
matrices.    Plots of the MSR as a function of the number of protein
groups and sample groups show that the MSR declines in a regular
pattern as the number of groups increases (\fref{scrmean}).
```{r scrmean}
scrMean <- apply(scrambled, 1:2, mean)
scrPivot <- pivot(scrMean)
colnames(scrMean) <- c("ProteinGroups", "SampleGroups", "MeanMSE")
scrMean <- as.data.frame(scrMean)
```
\begin{figure}
```{r fig=TRUE,echo=FALSE}
attach(scrMean)
interaction.plot(SampleGroups, ProteinGroups, MeanMSE, type='b')
detach()
```
\caption{Mean squared residuals in \textbf{column-scrambled} matrices
  as a function of the numbers of protein groups and sample groups.}
\label{scrmean}
\end{figure}

We can also compare the MSR from the random matrices and the
column-scrambled matrices (\fref{compared}).  While clearly strongly
related, there is a systematic shift that makes the MSR for the random
matrices slightly larger than the MSR for the scrambled matrices.
\begin{figure}
```{r fig=TRUE,echo=FALSE}
plot(ranMean$MeanMSE, scrMean$MeanMSE, pch=16,
     xlab="Random Matrices", ylab="Scrambled Matices")
abline(0,1, col='red')
```
\caption{Scatter plot of mean squared residual using random or
  scrambled matrices.}
\label{compared}
\end{figure}
\clearpage
## {Scoring}
The underlying statistical model used to fit the tiles is that the
(clustered) matrix can be divided into uniform tiles, each with its
own mean expression.  The residual errors that are ``unexplained'' by
these mean value are assumed to be independently and identically
distributed (IID), having a normal distribution with mean zero and
common standard deviation.  Given the estimated parameters (tile
means) from this model, we can compute the log likelihood of the
data. Note that we actually compute $-2$ log(likelihood), since that
is the standard term that shows up in definitiosn of AIC and BIC.  We
have defined a function to perform this comptuation for each number of
protein and sample groups, and we apply this function to both the
random and scrambled matrices.
```{r loglike}
ranLL <- n2loglik(ranMean)
scrLL <- n2loglik(scrMean)
```

Now we can plot the (-2) log-likelihood, the AIC, and the BIC as
functions of the number of estimated parameters (\fref{ranll}).  Note
that this number is a na\"ive estimate of the number of degrees of
freedom used to fit the data, since it ignores the fact that the data
was already used to run clustering algorithms. Ideally, for random
matrices, the minimum of the AIC, BIC, or both would be at the
starting point where there is only one protein group and one sample
group.
\begin{figure}
```{r fig=TRUE,echo=FALSE}
opar <- par(mfrow=c(2,2))
attach(ranLL)
plot(K, neg2ll, xlab="Degrees of Freedom", ylab="-2 Log(likelihood)")
plot(K, AIC, xlab="Degrees of Freedom", ylab="AIC")
plot(K, BIC, xlab="Degrees of Freedom", ylab="BIC")
detach()
attach(ranMean)
interaction.plot(SampleGroups, ProteinGroups, MeanMSE, type='b')
detach()
par(opar)
```
\caption{Scatter plots of the log likelihood, Akaike Information
  Criterion (AIC) and Bayes Information Criterion (BIC) as functions
  of the number of degrees of freedom (estimated parameters) in the
  tiling models.}
\label{ranll}
\end{figure}
\clearpage

# {Two-way Dendrogram Cuts on Real Data}
Now we cluster the data subset consisting of our actual measurements
on proteins in the \Sexpr{pathway} pathway.
```{r clusters}
sampleClades <- hclust(distanceMatrix(t(AMLRPPA), metric="pearson"), 
                       method="ward")
proteinClades <- hclust(distanceMatrix(AMLRPPA, metric="pear"), 
                        method="ward")
```
We fit a block-tile model on the real data, and compute the log
likelihood.
```{r storage}
storage <- blocker(AMLRPPA)
ourLL <- n2loglik(storage)
```
Now we look at the number of clades that would be selected by AIC or
BIC on the real data.  We expect both of these methods to
\textbf{overestimate} the number of clades, since they do not properly
corrrect for the approximate number of parameters used to fit the
dendrograms in the first place.
```{r }
wa <- which(ourLL$AIC==min(ourLL$AIC))
storage[wa,]

wb <- which(ourLL$BIC==min(ourLL$BIC))
storage[wb,]
```

Now we define our \textit{ad hoc} ``empirical information criterion''
(EIC), which no else currently uses because we just invented it. We
start by fitting a linear model to relate the observed log-likelihoods
on the real data to the ``empirically derived theoretical''
log-likelihoods from random data.  (At the moment, we do not care if a
linear model is the best way to relate these two quantities.  We are
only using this to get some sensible estimate of a ``magic''
correction factor.  We can, of course, plot the two quantities
against each other to see if they are anywhere near linear
(\fref{magic}).)  We are hoping for a magic number in the range 2--10,
which we might believe and might eventually be able to derive by some
theoretical argument.
```{r MAGIC}
lmod <- lm(ourLL$neg2ll ~ ranLL$neg2ll)
MAGIC <- coef(lmod)[2]
MAGIC
```

Now we define the EIC to be the number obtained by subtracting a
penalty equal to the ``magic'' multiple of the random-matrix MSR from
the observed MSR on the real data.  The ``optimal'' number of sample
and protein clades is then found by minimizing the EIC.
```{r EIC}
EIC <- ourLL$neg2ll - MAGIC*ranLL$neg2ll
w <- which(EIC == min(EIC))
storage[w,]
```

\begin{figure}
```{r fig=TRUE,echo=FALSE}
plot(ranLL$neg2ll, ourLL$neg2ll, pch=16,
     xlab="Random Log(likelihood)", ylab="Actual Log(likelihood)")
abline(0,1)
abline(coef(lmod), col="blue")
```
\caption{Scatter plot of $-2$ log(likelihood) for the random matrices
  and the actual data.  Blue line is the best linear fit of the data;
  black line is the identity line.}
\label{magic}
\end{figure}

We can plot the EIC as a function of the na\"ive number of degrees of
freedom (\fref{EIC}). This plot can be thought of as a collection of
overlaid plots for different numbers of protein clades.
\begin{figure}
```{r fig=TRUE,echo=FALSE}
plot(ourLL$K, EIC, pch=16, xlab="Degrees of Freedom", 
     ylab="(new) Empirical Information Criterion")
NP <- max(storage$ProteinGroups)
for (i in 1:NP) {
  w0 <- which(storage$ProteinGroups == i)
  lines(ourLL$K[w0], EIC[w0], col=cols[i])
}
legend("bottomright", paste("n =", 1:NP), col=cols[1:NP], lwd=2)
```
\caption{Scatter plot of the EIC as a function of the number of
  parameters (degrees of freedom) in the tiling models.}
\label{EIC}
\end{figure}

# {Modeling the Tiles (EIC)}
Having now computed what we think may be a reaonable estimate of the
optimal number of protein and sample clades, we can fit the block-tile
model for the full data matrix.
```{r model}
np <- storage$ProteinGroups[w]
ns <- storage$SampleGroups[w]
pgroup <- paste("p", cutree(proteinClades, k=np), sep='')
sgroup <- paste("p", cutree(sampleClades, k=ns), sep='')
rowv <- as.dendrogram(proteinClades)
colv <- as.dendrogram(sampleClades)
tdata <- data.frame(Y=as.vector(as.matrix(dat)),
                    P=rep(pgroup, each=nrow(dat)),
                    S=rep(sgroup, times=ncol(dat)))
model <- lm(Y ~ P*S, data=tdata)
anova(model)
```

```{r showme}
showme <- function(dataset, dir='none', main='', K=2, colmap=jetColors(64), symKey=TRUE) {
  temp <- t(truncscale(dataset, dir=dir, K=K))
  heatmap.2(temp,
          Rowv=rowv,  Colv=colv,
          ColSideColors=cols[cutree(sampleClades, ns)],
          RowSideColors=cols[cutree(proteinClades, np)],
          col=colmap, scale="none", zlim=c(-K, K),
          labCol=NA, cexRow=1, symkey=symKey, 
          density.info="none", trace="none", main=main, xlab="", ylab="")
}
```

```{r cmap}
cr0 <- colorRampPalette(c("cyan", "#77aa77", "yellow"))
crp <- colorRampPalette(c("blue", "#0088ff", cr0(5), "#ff8800", "red"))
cmap <- crp(128)

srp <- colorRampPalette(c("white", "purple"))
smap <- srp(128)

```
\begin{figure}
```{r fig=TRUE,echo=FALSE,width=6.5,height=2.5}
opar <- par(mai=c(1, 0.3, 0.1, 0.3))
image(seq(-2, 2, length=1024), 1:1, matrix(1:1024), col=cmap, 
      ylab='', xlab='', yaxt='n')
par(opar)
```
\caption{New color map.}
\label{cmap}
\end{figure}
\clearpage
\begin{figure}
```{r fig=TRUE,echo=FALSE}
kut <- 1.6
showme(AMLRPPA, "none", "Scaled Data", K=kut, colmap=cmap)
```
\caption{Heatmap of original scaled data.}
\label{scaled}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
rebox <-matrix(model$fit, ncol=ncol(dat))
dimnames(rebox) <- dimnames(AMLRPPA)
showme(rebox, "none", "Tiles", K=1, colmap=cmap)
```
\caption{Heatmap of tiles.}
\label{tiles}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
resbox <-matrix(model$res, ncol=ncol(dat))
dimnames(resbox) <- dimnames(AMLRPPA)
showme(resbox, "none", "Absolute Residuals", K=kut, colmap=cmap)
```
\caption{Heatmap of absolute residuals.}
\label{absres}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
showme(resbox, "col", "Relative Residuals", K=kut, colmap=cmap)
```
\caption{Heatmap of relative residuals.}
\label{relres}
\end{figure}
\clearpage

# {Modeling the Tiles (BIC)}
For comparison purposes, we can also use the estimated number of
clades coming from the Bayes Informaiton Criterion. 
```{r model.bic}
np <- storage$ProteinGroups[wb]
ns <- storage$SampleGroups[wb]
pgroup <- paste("p", cutree(proteinClades, k=np), sep='')
sgroup <- paste("p", cutree(sampleClades, k=ns), sep='')
rowv <- as.dendrogram(proteinClades)
colv <- as.dendrogram(sampleClades)
tdata <- data.frame(Y=as.vector(as.matrix(dat)),
                    P=rep(pgroup, each=nrow(dat)),
                    S=rep(sgroup, times=ncol(dat)))
model <- lm(Y ~ P*S, data=tdata)
anova(model)
```

\clearpage
\begin{figure}
```{r fig=TRUE,echo=FALSE}
kut <- 1.6
showme(AMLRPPA, "none", "Scaled Data", K=kut, colmap=cmap)
```
\caption{Heatmap of original scaled data (BIC mnodel).}
\label{scaled.bic}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
rebox <-matrix(model$fit, ncol=ncol(dat))
dimnames(rebox) <- dimnames(AMLRPPA)
showme(rebox, "none", "Tiles", K=1, colmap=cmap)
```
\caption{Heatmap of tiles (BIC model).}
\label{tiles.bic}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
resbox <-matrix(model$res, ncol=ncol(dat))
dimnames(resbox) <- dimnames(AMLRPPA)
showme(resbox, "none", "Absolute Residuals", K=kut, colmap=cmap)
```
\caption{Heatmap of absolute residuals (BIC model).}
\label{absres.bic}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
showme(resbox, "col", "Relative Residuals", K=kut, colmap=cmap)
```
\caption{Heatmap of relative residuals (BIC model).}
\label{relres.bic}
\end{figure}
\clearpage
# {Modeling the Tiles (Alternate EIC)}
For comparison purposes, we can also use the estimated number of
clades coming from a modified form ofthe EIC that uses a less
stringent criterion.
```{r model.eic2}
MAGIC <- coef(lmod)[2] / sqrt(2)
EIC2 <- ourLL$neg2ll - MAGIC*ranLL$neg2ll
w2 <- which(EIC2 == min(EIC2))
storage[w2,]

np <- storage$ProteinGroups[w2]
ns <- storage$SampleGroups[w2]
pgroup <- paste("p", cutree(proteinClades, k=np), sep='')
sgroup <- paste("p", cutree(sampleClades, k=ns), sep='')
rowv <- as.dendrogram(proteinClades)
colv <- as.dendrogram(sampleClades)
tdata <- data.frame(Y=as.vector(as.matrix(dat)),
                    P=rep(pgroup, each=nrow(dat)),
                    S=rep(sgroup, times=ncol(dat)))
model <- lm(Y ~ P*S, data=tdata)
anova(model)
```

\clearpage
\begin{figure}
```{r fig=TRUE,echo=FALSE}
kut <- 1.6
showme(AMLRPPA, "none", "Scaled Data", K=kut, colmap=cmap)
```
\caption{Heatmap of original scaled data (EIC2 mnodel).}
\label{scaled.eic2}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
rebox <-matrix(model$fit, ncol=ncol(dat))
dimnames(rebox) <- dimnames(AMLRPPA)
showme(rebox, "none", "Tiles", K=1, colmap=cmap)
```
\caption{Heatmap of tiles (EIC2 model).}
\label{tiles.eic2}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
resbox <-matrix(model$res, ncol=ncol(dat))
dimnames(resbox) <- dimnames(AMLRPPA)
showme(resbox, "none", "Absolute Residuals", K=kut, colmap=cmap)
```
\caption{Heatmap of absolute residuals (EIC2 model).}
\label{absres.eic2}
\end{figure}

\begin{figure}
```{r fig=TRUE,echo=FALSE}
showme(resbox, "col", "Relative Residuals", K=kut, colmap=cmap)
```
\caption{Heatmap of relative residuals (EIC2 model).}
\label{relres.eic2}
\end{figure}
\clearpage


# {R libraries used in the analyses}
```{r image,echo=F}
sessionInfo()
```

\end{document}


```{r eval=FALSE,echo=FALSE}
qqnorm(resbox)
qqline(resbox)
```


\begin{figure}
```{r fig=TRUE,echo=FALSE,eval=FALSE}
vibox <- NA*resbox
for (i in 1:np) {
  myp <- cutree(proteinClades, np)==i
  for (j in 1:ns) {
    mys <- cutree(sampleClades, ns)==j
    value <- mean(resbox[mys, myp]^2)
    vibox[mys, myp] <- value
  }
}

showme(log(vibox), "none", "Mean Square Residuals by Tile",  colmap=smap, symKey=FALSE)
```
\caption{Heatmap of absolute residuals.}
\label{absres}
\end{figure}



```{r echo=FALSE,eval=FALSE}
foo2 <- ranMean[ranMean$ProteinGroups==2,]
mymod <- nls(MeanMSE ~ alpha + beta*exp(-gamma*SampleGroups),
             start=list(alpha=1, beta=0.05, gamma=0.13), data=foo2)
mm <- coef(mymod)
attach(foo2)
plot(SampleGroups, MeanMSE, type='b')
lines(mm['alpha'] + mm['beta']*exp(-mm['gamma']*SampleGroups), col='red')
lines(SampleGroups, predict(mymod), col='blue')
detach()

attach(ranMean)
interaction.plot(SampleGroups, ProteinGroups, MeanMSE, type='b')
detach()
for (i in 2:6) {
  foo2 <- ranMean[ranMean$ProteinGroups==i,]
  mymod <- nls(MeanMSE ~ alpha + beta*exp(-gamma*SampleGroups),
               start=list(alpha=1, beta=0.05, gamma=0.13), data=foo2)
  mm <- coef(mymod)
  lines(foo2$SampleGroups, predict(mymod), col=i)
}

```

# References

[Weinstein97]
Weinstein JN, Myers TG, O'Connor PM, Friend SH, Fornace Jr AJ, Kohn KW, Fojo T,
Bates SE, Rubinstein LV, Anderson NL, Buolamwini JK, van Osdol WW, Monks AP,
Scudiero DA, Sausville EA, Zaharevitz DW, Bunow B, Viswanadhan VN, Johnson GS,
Wittes RE, Paull KD.
An information-intensive approach to the molecular pharmacology of cancer.
Science. 1997 Jan 17;275(5298):343-9. doi: 10.1126/science.275.5298.343.

[Eisen98]
Eisen MB, Spellman PT, Brown PO, Botstein D.
Cluster analysis and display of genome-wide expression patterns.
Proc Natl Acad Sci U S A. 1998 Dec 8;95(25):14863-8. doi: 10.1073/pnas.95.25.14863.

[Engle17]
Engle S, Whalen S, Joshi A, Pollard KS.
Unboxing cluster heatmaps.
BMC Bioinformatics. 2017 Feb 15;18(Suppl 2):63. doi: 10.1186/s12859-016-1442-6.

[charrad14]
Charrad M,  Ghazzali N, Boiteau V, Niknafs A.
NbClust: An R Package for Determining the Relevant Number of Clusters in a Data Set.
Journal of Statistical Software. 2014; 61(6):1-36,
url = http://www.jstatsoft.org/v61/i06/.
