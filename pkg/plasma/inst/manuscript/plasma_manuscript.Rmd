---
title: "plasma: Partial LeAst Squares for Multi-omics Analysis (manuscript)"
author: "Kevin R. Coombes"
data: "`r Sys.Date()`"
output:
  html_document:
    toc: true
---

```{r opts, echo=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=5)
options(width=96)
.format <- knitr::opts_knit$get("rmarkdown.pandoc.to")
.tag <- function(N, cap ) ifelse(.format == "html",
                                 paste("Figure", N, ":",  cap),
                                 cap)
```
# Introduction
Recent years have seen the development of numerous algorithms and computational packages for
the analysis of multi-omics data sets. At this point, one can find multiple review articles
summarizing progress in the field [@subramanian2020; @graw2021; @heo2021; @picard2021;
@reel2021; @vlachavas2021; @adossa2021]. As with other applications of
machine learning, the kinds of problems addressed by these algorithms are divided into
two categories: unsupervised (e.g., clustering or class discovery) or supervised
(including class comparison and class prediction) [@simon2003]. Advances in the area of unsupervised
learning have been broader and deeper than advances on supervised learning.

One of the most effective unsupervised methods is Multi-Omic Factor Analysis (MOFA)
[@argelaguet2018; @argelaguet2020]. A key property of MOFA is that it does not require
all omics assays to have been performed on all samples under study. In particular, it can
effectively discover class structure across omics data sets even when data for many
patients have only been acquired on a subset of the omics technologies. As of this
writing, we do not know of any supervised multi-omics method that can effectively learn
to predict outcomes when samples have only been assayed on a subset of the omics data sets.

MOFA starts with a standard method -- Latent Factor Analysis -- that is known to work 
well on a single omics data set. It then fits a coherent model that identifies latent factors
that are common to, and able to explain the data well in, all the omics data sets under
study. Our investigation (unpublished) of the factors found by MOFA suggests that, at
least in come cases, it is approximately equivalent to a two-step process:

1. Use principal components analysis to identify initial latent factors in each individual
   omics data set.
2. For each pair of omics data sets, use overlapping samples to train and extend models of
   each factor to the union of assayed samples.

That re-interpretation of MOFA suggests that an analogous procedure might work for supervised
analyses as well. In this article, we describe a two-step algorithm, which we call "_plasma_",
to find models that can predict time-to-event outcomes on samples from multi-omics data sets
even in the presence of incomplete data. We use partial least squares (PLS) for both steps,
using Cox regression to learn the single omics models and linear regression to learn how to
extend models from one omics data set to another. To illustrate the method, we use a subset
of the esophageal cancer (ESCA) data set from The Cancer Genome Atlas (TCGA).


# Methods
Our computational method is implemented and the data are available in the `plasma` package.
```{r pkgs}
suppressWarnings( library(plasma) )
packageVersion("plasma")
```

## Data
The results included here are in whole or part based upon data generated by the 
[TCGA Research Network](https://www.cancer.gov/tcga). We downloaded the entire esophageal
cancer Level 3 data set [@tcga2017] from the Genomics Data Commons (GDC) [@jensen2017] on
6 August 2018. We filtered the data sets so that only the most variable, and presumably
the most informative, features were retained. Here, we load this sample data set.
```{r data}
loadESCAdata()
sapply(assemble, dim)
```

1. From TCGA, we obtained 162 columns of clinical, demographic, and laboratory data on 185
   patients. We removed any columns that always contained the same value. We also removed
   any columns whose values were missing in more than 25% of the patients. We converted
   categorical variables into sets of binary variables using one-hot-encoding. We then
   separated the clinical data into three parts:
    1. Outcome (overall survival)
    2. Binary covariates (53 columns)
    3. Continuous covariates (6 columns)
1. Exome sequencing data for 184 patients with esophageal cancer was obtained as mutation allele
   format (MAF) files. We removed any gene that was mutated in fewer than 3% of the samples. The
   resulting data set contained 566 mutated genes.
2. Methylation data for 185 ESCA patients was obtained as beta values computed by the TCGA from
   Illumina Methylation 450K microarrays. We removed any CpG site for which the standard deviation
   of the beta values was less than 0.3. The resulting data set contained 1,454 highly variable
   CpG's.
3. Already normalized sequencing data on 2,566 microRNAs (miRs) was obtained for 185 patients.
   We removed any miR for which the standard deviation of normalized expression was less
   than 0.05, which left 926 miRs in the final data set.
4. Already normalized sequencing data on 20,531 mRNAs was obtained in 184 patients. We removed
   any mRNA whose mean normalized expression was less than 6 or whose standard deviation was less
   than 1.2. The final data set included 2,520 mRNAs.
5. Normalized expression data from reverse phase protein arrays (RPPA) was obtained from
   antibodies targeting 192 proteins in 126 patients. All data were retained for further analysis.

Finally, in order to be able to illustrate the ability of the plasma algorithm to work in
the presence of missing data, we randomly selected 10% of the patients to remove from
the miRSeq data set (leaving 166 patients) and 15% of the patients to remove from the
mRNASeq data set (leaving 157 patients). We provid a summary of the outcome data below.

## Imputation
We recommend imputing small amounts of missing data in the input data sets. The underlying issue
is that the PLS models we use for individual omics data sets will not be able to make predictions
on a sample if even one data point is missing. As a result, if a sample is missing at least one
data point in every omics data set, then it will be impossible to use that sample at all.

For a range of available methods and R packages, consult the
[CRAN Task View on Missing Data](https://CRAN.R-project.org/view=MissingData).
We also recommend the [R-miss-tastic web site on missing data](https://rmisstastic.netlify.app/).
Their simulations suggest that, for purposes of producing predictive models from omics data,
the imputation method is not particularly important. Because of the latter finding, we have only
implemented two simple imputation methods in the `plasma` package:

1. `meanModeImputer` will replace any missing data by the mean value of the observed data if
   there are more than five distinct values; otherwise, it will replace missing data by the mode.
   This approach works relatively well for both continuous data and for binary or small categorical
   data.
2. `samplingImputer` replaces missing values by sampling randomly from the observed data distribution.

```{r impute}
set.seed(54321)
imputed <- lapply(assemble, samplingImputer)
```

## Computational Approach
The `plasma` algorithm is based on Partial Least Squares (PLS), which has been shown to be
an effective method for finding components that can predict clinically interesting outcomes
[@bastien2015]. The workflow of the plasma algorithm is illustrated in **Figure 1** in the
case of three omics data sets. First, for each of the omics data sets, we apply the PLS Cox
regression algorithm (`plsRcox` Version `r packageVersion("plsRcox")` [@bertrand2021]) to the
time-to-event outcome data to learn three separate predictive models (indicated in red, green,
and blue, respectively). Each of these models may be incomplete, since they are not defined
for patients who have not been assayed (shown in white) using that particular omics technology.
Second, for each pair of omics data sets, we apply the PLS linear regression algorithm
(`pls` Version `r packageVersion("pls")` [@mishra2022]) to learn how to predict the coefficients of
the Cox regression components from one data set using features from the other data set. This
step extends (shown in pastel red, green, and blue, resp.) each of the original models,
in different ways, from the intersection of samples assayed on both data sets to their union.
Third, we average all of the different extended models (ignoring missing data) to get a single
coherent model of component coefficients across all omics data sets. Assuming that this process
has been applied to learn the model from a training data set, we can evaluate the final Cox
regression model on both the training set and a test set of patient samples.

```{r fig01, out.width = "100%", fig.cap = .tag(1, "Workflow schematic for plasma algorithm with three omics data sets. See main text for an explanation."), echo = FALSE}
SF <- system.file("Figure/methods.png", package = "plasma")
knitr::include_graphics(SF)
rm(SF)
```

All computations were performed in `r R.version.string` of the R Statistical Software Environment
[@Rbook]. Cox proportioanl hazards models for survival analysis were fit using version
`r packageVersion("survival")` of e `survival` R package. We used additional exploratory graphical
tools from version `r packageVersion("beanplot")` of the `beanplot` R package [@kampstra2008] and
version `r packageVersion("Polychrome")` of the `Polychrome` R package [@coombes2019].


## Terminology
Because of the layered nature of the plasma algorithm, we intend to use the following terminology
to help clarify the later discussions.

1. The input data contains a list of _omics data sets_.
2. Each omics data set contains measurements of multiple _features_.
3. The first step in the algorithm uses PLS Cox regression to find a set of _components_.
   Each component is a linear combination of features. The components are used as predictors
   in a Cox proportional hazards model, which predicts the log hazard ratio as a linear
   combination of components.
4. The second step in the algorithm creates a secondary layer of components. We do not give
   these components a separate name. They are not an item of particular focus; we view them
   as a way to extend the first level components to more samples by "re-interpreting" them
   in other omics data sets.

## Preparing the Data
To be consistent with the `MOFA2` R package [@argelaguet2020], all of the data sets are
arranged so that patient samples are columns and assay features are rows. Our first task
is to pad each data set with appropriate `NA`'s to ensure that each set includes the same
patient samples in the same order, where that order matches the outcome data frame.
```{r prep}
MO <- prepareMultiOmics(imputed, Outcome)
summary(MO)
```

We see that the number of patients in each data set is now equal to the number of patients
with clinical outcome data.


## Split Into Training and Test
As indicated above, we want to separate the data set into training and test samples. We will
use 60% for training and 40% for testing.
```{r split}
set.seed(54321)
splitVec <- rbinom(nrow(Outcome), 1, 0.6)
```

**Figure 2** presents a graphical overview of the number of samples (`N`) and the number of
features (`D`) in each omics component of the training and test sets.

```{r fig02, fig.cap = .tag(2, "Overview of training and test data."), fig.width=9, fig.height=8}
trainD <- MO[, splitVec == 1]
testD <- MO[, splitVec == 0]
opar <- par(mai = c(1.02, 1.32, 0.82, 0.22), mfrow = c(1,2))
plot(trainD, main = "Train")
plot(testD, main = "Test")
par(opar)
```

# Results

## Individual PLS Cox Regression Models
The first step of the `plasma` algorithm is to fit PLS Cox models on each omics data set using
the function `fitCoxModels`. The returned object of class `MultiplePLSCoxModels` contains a list
of `SingleModel` objects, one for each assay, and within each there are three regression models:

* The `plsRcoxmodel` contains the coefficients of the components learned by PLS Cox regression.
  The number of components is determined automatically as a function of the logarithm of the
  number of features in the omics data set. The output of this model is a continuous prediction
  of "risk" for the time-to-event outcome of interest.
* Two separate models are constructed using the prediction of risk on the training data.
    + The `riskModel` is a `coxph` model using continuous predicted risk as a single predictor.
    + The `splitModel` is a `coxph` model using a binary split of the risk (at the median) as
      the predictor.

```{r firstPass, results = "hide"}
suppressWarnings( firstPass <- fitCoxModels(trainD, timevar = "Days",
                          eventvar = "vital_status", eventvalue = "dead") )
```

```{r showFrist}
summary(firstPass)
```
```{r fig03, fig.width = 8, fig.height = 12, fig.cap = .tag(3, "Kaplan-Meier plots of overall survival on the training set from separate PLS Cox omics models")}
if (!interactive()) {
  plot(firstPass, legloc = "bottomleft") # margins too small inside RStudio window
}
```

On the training set, each of the seven contributing omics data sets is able to find a PLS
model that can successfully separate high risk from low risk patients (**Figure 3**).

## Extend Model Components Across Omics Data Sets
The second step of the algorithm is to extend the individual omics-based models across other omics
data sets. This step is performed using the `plasma` function, which takes in the previously
created objects of class `multiOmics` and `MultiplePLSCoxModels`. The function operates
iteratively, so in our case there are seven different sets of predictions of the PLS
components. These different predictions are averaged and saved internally as a data frame
called `meanPredictions`. The structure of models created and stored in the `plasma` object is
the same as for the separate, individual, omics models. **Figure 4** shows the Kaplan-Meier plot
using the predicted risk, split at the median value, on the training data set.

```{r fig04, fig.cap = .tag(4, "Kaplan-Meier plot of overall survival on the training set using the unified `plasma` Cox model.")}
pl <- plasma(MO, firstPass)
plot(pl, legloc = "topright", main = "Training Data", xlab = "Time (Days)")
```

## Independent Test Set
Now we want to see how well the final composite model generalizes to our test set. **Figure 5**
uses the predicted risk, split at the median of the training data, to construct a Kaplan-Meier
plot on the test data. The model yields a statistically significant (p = 0.0063) separation of
outcomes between the high and low risk patients.

```{r fig05, fig.cap = .tag(5, "Kaplan-Meier plot of overall survival on the test set.")}
testpred <- predict(pl, testD)
plot(testpred, main="Testing Data", xlab = "Time (Days)")
```

## Interpretation
At this point, our model appears to be a fairly complex black box. We have constructed a matrix
of components, based on linear combinations of actual features in different omics data sets.
These components can then be combined in yet another linear model that predicts the time-to-event
outcome through Cox regression. In this section, we want to explore how the individual features
from different omics data sets contribute to different model components.

Our first act toward opening the black box is to realize that not all of the components discovered
from the individual omics data sets survived into the final composite model. Some components were
eliminated because they appeared to be nearly linearly related to components found in other omics
data sets. So, we can examine the final composite model more closely.
```{r fullModel}
pl@fullModel
temp <- terms(pl@fullModel)
mainterms <- attr(temp, "term.labels")
rm(temp)
mainterms
```
We see that at least one component discovered from four of the five "true" omics data sets
survived in the final model; only the miR components failed to make the cut. In addition, one
component from the binary clinical data ws retained in the final model.

Our interest now turns to understanding how the features from individual omics data
sets contribute to the components that are used in the final model. As mentioned 
earlier, these contributions are mediated through two levels of linear regression
models when extending a model from data set A to data set B. A linear combination
of features from set B is used to define the secondary level of components; then
a linear combination of these components is used to predict the components of the
single Cox model built that had been from set A. These weights can be combined and
extracted using the `getAllWeights` function, and can then be explored.

### Clinical Binary Data
We use the binary clinical data set to begin illustrating one method for interpreting
the components.
```{r fig06, fig.cap = .tag(6, "Unscaled heatmap of the contributions of binary clinical features to all components (purple = retained in final model, green = not retained)."), fig.height = 7}

library(oompaBase)
HG <-  blueyellow(64)
cbin <- getAllWeights(pl, "ClinicalBin")
compcolors <- c("forestgreen", "purple")[1 + 1*(colnames(cbin@contrib) %in% mainterms)]
heat(cbin, cexCol = 0.9, cexRow = 0.5, col = HG, ColSideColors = compcolors)
```

**Figure 6** shows the raw weights for each clinical binary feature in all of the original
omics components. We would like to simplify this plot in several ways. First, we can remove
any components that were not retained in the final model (indicated by the green color bar
in the top dendrogram). Second, we hypothesize that some
components intrinsically have a wider spread of weights, and that it might be more important
to scale the components consistently to look at the relative contributions. Finally, we can
remove any features that seem to make no contributions to any of the components; that is;
those that do not have highly ranked weights (by absolute value) in any component. 
```{r shrink}
shrink <- function(dset, N) {
  dset@contrib <- scale(dset@contrib)               # standardize
  feat <- unique(unlist(as.list(getTop(dset, N))))  # remove useless features
  dset@contrib <- dset@contrib[feat, mainterms]     # remove unused components
  dset
}
```

```{r fig07, fig.cap = .tag(7, "Scaled heatmap of the contributions of filtered binary clinical features to important components."), fig.height = 7}
xbin <- shrink(cbin, 4)
heat(xbin, cexCol = 0.9, cexRow = 0.9, col = HG)
```

In **Figure 7**, we can identify strong contrasts between several pairs of variables. For example,
one set of components is enriched with white, never smokers, who still have evidence of tumors, at
stage T3 and grade 3 in the lower third of the esophagus (ICD-10 code C15.5), while another group
is enriched for Asian, current smokers, who are tumor-free, with stage N0, T2 tumors from the
lower third of the esophagus (ICD-10 code C15.4).

### mRNA-Sequencing Data
We can apply the same method to visualize contributors from each of the omics data sets.
As a second illustration, we look at the standardized weights from the mRNA data set in the components
that are part of the final model, keeping only those features that are highly ranked by absolute
weight in at least one component (**Figure 8**).
```{r fig08, fig.cap = .tag(8, "Scaled heatmap of the contributions of filtered mRNA features to important components"), fig.height = 7}
mrna <- getAllWeights(pl, "mRNASeq")
xmrna <- shrink(mrna, 7)
tmp <- rownames(xmrna@contrib)
rownames(xmrna@contrib) <- sapply(strsplit(tmp, "\\."), function(x) x[1])
heat(xmrna, cexCol = 0.9, cexRow = 0.6, col = HG)
```

## Uniting the Contributors
One difficulty with the heatmaps in the previous section is that they are focused on individual
input data sets, and not on individual components. In order to fully understand which features
contribute, for example, to the first mutation component (MAF1), one would have to scan all the
heatmaps from all the datasets and then try to combine the influences. In order to help with that procedure,
we can merge all the contributions into a single data frame, with an accompanying factor tracking
the source data set.
```{r contra}
CW <- combineAllWeights(pl)
contra <- CW@combined
datasrc <- CW@dataSource
```

**Figure 9** displays the mean, standard deviation (SD), median, and median absolute deviation (MAD)
of the weight-contributions for each data set in each component. 
```{r fig09, fig.cap = .tag(9, "Summary statistics of weights by component and dataset."), fig.width = 10, fig.height = 10}
image(CW)
```

## Standardized Weights
To remain consistent with the previous heatmaps, we have standardized the weights in each data set
and component. In **Figure 10**, we create beanplots showing the distributions of weights arising
from each data set in each (retained) component. (Similar plots for the raw weights are available
in **Supplementary Data**.) Some data sets have very different contribution patterns than others.
For example, the miRSeq data set appears to have significant outliers making large contributions
in almost every component, the MAF and RPPA data sets also frequently (but not always) include
such outliers.
```{r fig10, fig.cap = .tag(10, "Distributions of standardized weights by data set and component."), fig.width = 10, fig.height = 10}
library(beanplot)
library(Polychrome)
data(palette36)
foo <- computeDistances(palette36[3:36])
colist <- as.list(palette36[names(foo)[1:7]])
brute <- stdize(CW, "standard")
opar <- par(mfrow = c(3,3), mai = c(0.2,0.2, 0.5, 0.2))
for (i in which(colnames(contra) %in% mainterms)) {
  beanplot(brute[, i] ~ datasrc, what = c(1,1,1,0), col = colist,
           main = paste("Std Wts, Component", i))
}
par(opar)
rm(opar)
```

We also include plots of the histograms of distributions by component (**Figure 11**). None of
these really looks quite normal; almost all have some slightly odd shape.
```{r fig11, fig.cap = .tag(11, "Histogram of standardized weights by component."), fig.width = 10, fig.height = 10}
opar <- par(mfrow = c(3, 3), mai = c(0.2,0.2, 0.5, 0.2))
for (i in which(colnames(contra) %in% mainterms)) {
  hist(brute[,i], breaks = 77, main = paste("Component", i))
}
par(opar)
rm(opar)
```


## Data Set Sources of Top Twenty Lists
Next, we want to see how many items in the lists of "top twenty" contributers to each component
come from each data set. The results are shown in **Figure 12**. Using the raw weights, the vast
majority of contributions come from the clinical binary data, with secondary contributions from
the MAF and RPPA data sets (as we expected from the above distribution plots). After standardization,
most of the contributions arise from miRs, but the methylation, mRNA and, to a lesser extent, the
MAF and RPPA data sets also are present.
```{r fig1, fig.cap = .tag(12, "Number of contributers to top twenty lists."), fig.width=9, fig.height=6}
top20 <- apply(contra, 2, function(X) {
  A <- abs(X)
  S <- rev(sort(A))
  which(A > S[21])
})
top20types <- apply(top20, 2, function(X) {
  table(datasrc[X])
})

chop20 <- apply(brute, 2, function(X) {
  A <- abs(X)
  S <- rev(sort(A))
  which(A > S[21])
})
chop20types <- apply(chop20, 2, function(X) {
  table(datasrc[X])
})



opar <- par(mfrow = c(1, 2))
image(1:7, 1:24, top20types, main = "Raw Weights", ylab = "Components", xlab = "Data Sets")
mtext(levels(datasrc), side = 3, at = 1:7, line = 0)
image(1:7, 1:24, chop20types, main = "Standardized Weights", ylab = "Components", xlab = "Data Sets")
mtext(levels(datasrc), side = 3, at = 1:7, line = 0)
par(opar)
rm(opar)
```

## Overall Distribution of Weights
In **Figure 13**, we pool all the weights (across all data sets and all components) to look at
histograms of the distributions. We also overlay the theoretical normal distribution that one
would expect to see. Using the usual mean and distribution (right panel), the actual weights
are slightly more conservative (i.e., concentrated near zero) than expected. This figure
suggests that we might want to use standardization, and decide on significance purely from the
theoretical normal distribution rather than from deviations away from that distribution.
```{r fig13, fig.cap = .tag(13, "Histograms of all weights (combined)."), fig.width=9, fig.height=6}
opar <- par(mfrow = c(1, 2))
hist(contra, breaks = 123, main = "Raw Weights", prob = TRUE)
xx <- seq(-10, 10, length=1001)
yy <- dnorm(xx, mean(contra), sd(contra))
lines(xx, yy, col = "red", lwd=2)
hist(brute, breaks = 123, main = "Standardized Weights", prob = TRUE)
yy <- dnorm(xx)
lines(xx, yy, col = "red", lwd=2)
par(opar)
rm(opar)
```

## Number of Contributers Selected by Normal Significance
Finally, we create yet another image (**Figure 14**), counting the number of significant features
from each data set for each component, when using a significance cutoff of 5% derived from the
standard normal distribution. We feel that this result is more reasonable than any thing we got
just by looking at the top 20 lists. Most contributions come from the biggest omics data sets
(mRNA, methylation, and miR) with fewer from MAF, RPPA, and clinical binary.
```{r fig14, fig.cap = .tag(14, "Number of significant contributions by data set and component."), fig.width=6, fig.height=6}
Q <- qnorm(0.975) # two-sided 5% cutoff
top1p <- aggregate(brute, list(datasrc), function(X) sum(abs(X) > Q)) # top 5 percent
rownames(top1p) <- top1p[, 1]
top1p <- as.matrix(top1p[, -1])
top1p <- top1p[, mainterms]
image(1:7, 1:9, top1p, ylab = "Components", xlab = "Data Sets")
mtext(levels(datasrc),side = 3, at = 1:7, line = 0)
```

## Interpeting the MAF1 Component
In the final Cox proportional hazards model of overall survival, the component with the
largest hazard ratio was "`MAF1`" (the first feature discovered from the MAF mutation data
set), for which each one unit increase in the component corresponds to a 9-fold increase
in the hazard. Our next goal is to find a biological interpretation of this component.
First, here is an overview of all the contributing features.
```{r interpret}
pickA <- interpret(CW, "MAF1", 0.05)
summary(pickA)
```

We start by looking more closely at the clinical features.
```{r clinfeat}
pickA[1:4, ]
```
Because of our decision to use one-hot encoding of categorical variables, our data set includes
separate features for "male" and"female". Both terms are strongly related to the MAF1 component,
but (as one would hope) with approximately equal standardized weights but opposite signs. Being
female decreases the hazard; being male increases it. Since the coefficient of `MAF1` in the
final model of overall survival is itself positive, we can infer the direction that the hazard
changes.  It is harder to "eyeball" the magnitude of the change in the hazard, since these
coefficients only measure the relative contribution of these factors to the MAF1 component. 

Many of the feature names obtained from TCGA include extra annotations that we won't use later,
so we are going to simplify them.


This code gets out all of the illumina genes and not just the first element of the list

```{r}
library(dplyr)
library(readr)
library(tidyr)
```

```{r}
illumina<- read_csv("https://webdata.illumina.com/downloads/productfiles/humanmethylation450/humanmethylation450_15017482_v1-2.csv", skip=7) 
illuminaselect <- illumina %>% select( c("IlmnID", "UCSC_RefGene_Name"))
illuminaselect2<- separate_rows(illuminaselect, UCSC_RefGene_Name, sep=";")
illuminaselect2 <- as.data.frame(illuminaselect2)
illuminaselect3<- illuminaselect2 [which(illuminaselect2$IlmnID %in% pickA$Feature),]
illuminaselect4<- illuminaselect3[match(pickA$Feature[ pickA$Source=="Meth450"], illuminaselect3$IlmnID),]
illuminaselect4$UCSC_RefGene_Name[which(is.na(illuminaselect4$UCSC_RefGene_Name))] <- ""
```

```{r simplifyFeatureNames}
rap <- pickA$Feature[pickA$Source == "RPPA"]
rap <- sapply(strsplit(rap, "\\."), function(x) x[1])
map <- pickA$Feature[pickA$Source == "MAF"]
nap <- pickA$Feature[pickA$Source == "mRNASeq"]
nap <- sapply(strsplit(nap, "\\."), function(x) x[1])
nap <- nap[-1]
nick <- rep("", nrow(pickA))
nick[pickA$Source == "RPPA"] <- rap
nick[pickA$Source == "MAF"] <- map
nick[pickA$Source == "mRNASeq"] <- c("", nap)
nick[pickA$Source=="Meth450"]<- illuminaselect4$UCSC_RefGene_Name
pickA$Nickname <- nick
#write.csv(pickA, file = "pickMAF1.csv")
```

Here are the mutated genes (from the MAF data set) associated with the component "`MAF1`".
```{r map}
pickA[nick %in% map, ]
```
Note that they all have negative coefficients, meaning that having these mutations decreases the
effect of this component. Since the coefficient of `MAF1` in the final model of overall survival
is itself positive, that means that having any of these mutations decreases the hazard for that
patient. Here are the Entrez Gene descriptions of the genes:

CFAP54 (Cilia And Flagella Associated Protein 54)
:  Predicted to be involved in cilium assembly; cilium movement involved in cell motility; and spermatogenesis. Predicted to act upstream of or within cerebrospinal fluid circulation; motile cilium assembly; and mucociliary clearance. Predicted to be located in axoneme. 

DNAH9 (Dynein Axonemal Heavy Chain 9)
:  This gene encodes the heavy chain subunit of axonemal dynein, a large multi-subunit molecular motor. Axonemal dynein attaches to microtubules and hydrolyzes ATP to mediate the movement of cilia and flagella.

DYNC2H! (Dynein Cytoplasmic 2 Heavy Chain 1)
:  This gene encodes a large cytoplasmic dynein protein that is involved in retrograde transport in the cilium and has a role in intraflagellar transport, a process required for ciliary/flagellar assembly. Mutations in this gene cause a heterogeneous spectrum of conditions related to altered primary cilium function and often involve polydactyly, abnormal skeletogenesis, and polycystic kidneys.

FBN3 (Fibrillin 3)
:  This gene encodes a member of the fibrillin protein family. Fibrillins are extracellular matrix molecules that assemble into microfibrils in many connective tissues. This gene is most highly expressed in fetal tissues and its protein product is localized to extracellular microfibrils of developing skeletal elements, skin, lung, kidney, and skeletal muscle. This gene is potentially involved in Weill-Marchesani syndrome.

MYH13 (Myosin Heavy Chain 13)
:  Predicted to enable microfilament motor activity. Predicted to be involved in muscle contraction. Predicted to act upstream of or within cellular response to starvation. Located in extracellular exosome.

PCDHA12 (Protocadherin Alpha 12)
:  This gene is a member of the protocadherin alpha gene cluster, one of three related gene clusters tandemly linked on chromosome five that demonstrate an unusual genomic organization similar to that of B-cell and T-cell receptor gene clusters. The alpha gene cluster is composed of 15 cadherin superfamily genes related to the mouse CNR genes and consists of 13 highly similar and 2 more distantly related coding sequences. The tandem array of 15 N-terminal exons, or variable exons, are followed by downstream C-terminal exons, or constant exons, which are shared by all genes in the cluster. The large, uninterrupted N-terminal exons each encode six cadherin ectodomains while the C-terminal exons encode the cytoplasmic domain. These neural cadherin-like cell adhesion proteins are integral plasma membrane proteins that most likely play a critical role in the establishment and function of specific cell-cell connections in the brain. 

These descriptions clearly indicate some common functional relationships between the mutated genes,
including a role in cilia, flagella, and microfibrils.

We then extracted all gene names from the MAF, mRNASeq, and RPPA data sets and used thm to perform a
gene enrichment (pathway) analysis using ToppGene [@chen2009]. Associated GeneOntology Biological Process
categories included keratinization, epidermal and epithelial cell development, cell adhesion,
intermediate filament organization, and wound healing. GeneOntology Cellular Components included
cell-cell junctions, extracellular matrix, and intermediate filaments. Associated human phenotypes
included hyperkeratosis (particularly follicular hyperkeratosis), epidermal thickening, and oral
leukoplakia. Associated pathways included keratinization, gap junction assembly and trafficking,
and both ErbB and mTOR signaling. Associated cytogenetic regions included 1q21-1q22, 18q12.1,
and 12q12.13. Associated gene families included cadherins, kallikreins, keratins, and gap-junction
proteins. Associated diseases included hyperkertosis, squamous cell carcinoma of the head and neck,
intraepithelial neoplasia, endometrial carcinoma, basal-like breast carcinoma, and esophageal carcinoma.

## Export ToppGene queries for each component

Look at the components that were picked out in the final model, in addition to MAF1.

```{r}
print(mainterms)
mylist<- list()

for (i in 1:length(mainterms)){

pickA <- interpret(CW, mainterms[i], 0.05)

rap <- pickA$Feature[pickA$Source == "RPPA"]
rap <- sapply(strsplit(rap, "\\."), function(x) x[1])
map <- pickA$Feature[pickA$Source == "MAF"]
nap <- pickA$Feature[pickA$Source == "mRNASeq"]
nap <- sapply(strsplit(nap, "\\."), function(x) x[1])
nap <- nap[-1]
nick <- rep("", nrow(pickA))
nick[pickA$Source == "RPPA"] <- rap
nick[pickA$Source == "MAF"] <- map
nick[pickA$Source == "mRNASeq"] <- c("", nap)

illuminaselect <- illumina %>% select( c("IlmnID", "UCSC_RefGene_Name"))
illuminaselect2<- separate_rows(illuminaselect, UCSC_RefGene_Name, sep=";")
illuminaselect2 <- as.data.frame(illuminaselect2)
illuminaselect3<- illuminaselect2 [which(illuminaselect2$IlmnID %in% pickA$Feature),]
illuminaselect4<- illuminaselect3[match(pickA$Feature[ pickA$Source=="Meth450"], illuminaselect3$IlmnID),]
illuminaselect4$UCSC_RefGene_Name[which(is.na(illuminaselect4$UCSC_RefGene_Name))] <- ""

nick[pickA$Source=="Meth450"]<- illuminaselect4$UCSC_RefGene_Name

pickA$Nickname <- nick  
  
  
mylist[[i]] <- pickA
}

names(mylist) <- mainterms
```

```{r}
for (i in 1:length(mylist)){
  write.table(mylist[[i]]$Nickname, file=file.path("ToppGeneStuff", paste0("pick_", names(mylist)[i], ".txt")), quote = FALSE, 
              col.names =FALSE, row.names = FALSE)
}
```


Read in the .txt files containing results from ToppGene.
Some interesting features to subset on are GO: Biological Process, Pathway, Coexpression, Coexpression Atlas, ToppCell Atlas, and Disease. These seem to be relevant to our interests and have a decent number of "Genes from Input".
Take the top 20 (based on lowest pvalues) of these enrichments and create a list of dataframes.

```{r}
readinthese <- file.path("ToppGeneStuff", paste0("toppgene_", mainterms))
interested<- c("GO: Biological Process", "Pathway", "Coexpression", "Coexpression Atlas", "ToppCell Atlas", "Disease")
cutoffN <- 5

toppgeneres <- list()
for (i in 1:length(readinthese)){
  temp <- read.table(paste0(readinthese[i],".txt"), sep="\t", header=TRUE, fill=TRUE, quote="")
  temp2 <- temp[which(temp$Category %in% interested),]
  
  yeehaw <- list()
  
  for (k in 1:length(interested)){
    temp3 <-temp2[temp2$Category==interested[k],]
    temp4 <- head(temp3[order(temp3$p.value, decreasing = FALSE),], cutoffN)
    yeehaw[[k]] <- temp4
    yeet <- do.call(rbind, yeehaw)
    
  }
    toppgeneres[[i]] <- yeet
}

names(toppgeneres) <- mainterms

```

```{r}
d<- do.call(rbind, toppgeneres) %>% 
  mutate( ComponentName =sapply(strsplit(rownames(.), "\\."),  `[[`, 1) ) %>% 
  select(ComponentName, everything()) %>%
  mutate(neglogpval = - log10(p.value))
```

```{r}
library(ggplot2)
```

```{r}
pdf(file=file.path("ToppGeneStuff", "toppgene_bubble.pdf"),width=20, height=20)
d %>% ggplot(aes(x=Name, y=ComponentName, size=as.numeric(Hit.Count.in.Query.List)))+
  geom_point(aes(color=neglogpval))+
  scale_colour_gradient(low = "pink", high="darkred")+
  scale_size(range=c(1,10), name="Hit Count in Query")+
  scale_x_discrete(guide=guide_axis(angle=90))+
  theme(panel.grid.major=element_line(colour="black"), 
        text=element_text(size=10))
dev.off()
```

Clustering the components for a neater visual:

```{r}
uhh <- d[,c("ComponentName", "Name", "neglogpval")]

uhh[uhh==""]<-NA

uhh2 <- uhh %>% pivot_wider(values_from = neglogpval, names_from = Name, values_fn = mean) 

uhh2[is.na(uhh2)]<-0

h <- hclust(d=dist(uhh2))

ComponentNameNew<- uhh2$ComponentName[ order.dendrogram(as.dendrogram(h)) ]
```

```{r}
myL <-list()

for (i in 1:length(ComponentNameNew)){
  
d_sub <- d[ComponentNameNew[i] == d$ComponentName,]

myL[[i]] <- d_sub  
}
d_new <- do.call(rbind, myL)
```

```{r}
pdf(file=file.path("ToppGeneStuff", "toppgene_bubble_clustered.pdf"),width=20, height=22)
d_new %>% ggplot(aes(x=Name, y=ComponentName, size=as.numeric(Hit.Count.in.Query.List)))+
  geom_point(aes(color=neglogpval))+
  scale_colour_gradient(low = "pink", high="darkred")+
  scale_size(range=c(1,10), name="Hit Count in Query")+
  scale_x_discrete(guide=guide_axis(angle=90))+
  scale_y_discrete(limits=d_new$ComponentName)+
  theme(panel.grid.major=element_line(colour="black"), 
        text=element_text(size=10))
dev.off()
```

We see that components can be reasonably grouped together based on the top 5 items from the ontology categories we have chosen from ToppFunn (GO: Biological Process, Pathway, Coexpression, Coexpression Atlas, ToppCell Atlas, and Disease). In the largest group, we see that Meth4504, Meth4502, ClinicalBin1, mRNASeq1, Meth4503, and MAF1 are quite similar to each other. This group appears to be enriched for the term "Squamous cell". The only thing separating mRNASeq1, Meth4503, and MAF1 are two myeloid-monocyte cell signatures and "Squamous cell carocinoma of the head and neck". RPPA2 and RPPA3 are similar to each other and distinct from the group discussed previously in terms of enriched ontologies. Meth4501 also appears to be unique, and is notably the only component containing the term "adenocarcinoma" in its ToppFunn result.

# Some unused code

```{r echo = FALSE, eval = FALSE}
data("tfESCA")
shortTFname <- sapply(foo <- strsplit(tfESCA$ID, "\\."), function(X) paste(X[3:4], collapse="."))
puff <- sapply(foo, function(X) X[[4]])
shortTFname <- sub("A$", "", shortTFname)
rownames(tfESCA) <- shortTFname
data("mirESCA")
shortMIRname <- sapply(strsplit(mirESCA$ID, "\\."), function(X) paste(X[3:4], collapse = "."))
rownames(mirESCA) <- shortMIRname

barf <- tfESCA[rownames(mirESCA),] # only two disagreements
which(barf$Type != mirESCA$Type)

temp <- tfESCA[puff != "11A", ]
krak <- sapply(strsplit(temp$ID, "\\."), function(X) X[[3]])
w <- which(duplicated(krak))
if(any(w)) {
  temp <- temp[-w,]
  krak <- krak[-w]
}
rownames(temp) <- krak
all(rownames(temp) %in% rownames(Outcome))
outc <- Outcome[rownames(temp),]
MP <- pl@meanPredictions[rownames(temp),]
plot(MP[, "MAF1"] ~ factor(temp$Type))
t.test(MP[, "MAF1"] ~ factor(temp$Type)) # not significant


drat <- data.frame(outc, Type = temp$Type)

onemod <- coxph(Surv(Days, vital_status == "dead") ~ Type, data = drat)
onemod # not significant
plot(survfit(Surv(Days, vital_status == "dead") ~ Type, data = drat))
legend("topright", unique(drat$Type))

drago <- data.frame(Outcome[-w,], t(imputed$ClinicalBin)[-w,], MP)
onemod <- coxph(Surv(Days, vital_status == "dead") ~ gender.male + MAF1, data = drago)
step(onemod) 
```


```{r echo=FALSE, eval = FALSE}
library("IlluminaHumanMethylation450kanno.ilmn12.hg19")
data(IlluminaHumanMethylation450kanno.ilmn12.hg19)
```


```{r Rankedweights, echo = FALSE, eval = FALSE, out.width="50%"}
n=10 # top 10
dflist = mget(ls(pattern="x[A-Za-z]"))
dflist_contrib<-list()
# need to give unique names for variables based on which assay they came from, add a prefix
for (i in 1:length(dflist)){
 rownames(dflist[[i]]@contrib) <- 
   paste( as.character(dflist[[i]]@datasets) , rownames(dflist[[i]]@contrib) , sep="_")
 dflist_contrib[[i]] <-dflist[[i]]@contrib
}
# rbind all of the Formal class Contributions:
rbinded<- do.call(rbind, dflist_contrib)

# make a copy and save the signs
rbinded_signs <- rbinded
rbinded_signs[rbinded>0]<-"+"
rbinded_signs[rbinded<0]<-"-"

for (j in 1:ncol(rbinded)){

o <- order(abs(rbinded[,j]), decreasing = TRUE)  

weightsorted<- abs(rbinded)[o,j]
rbinded_signs_sorted <- rbinded_signs[o,j]

weightdf <- data.frame(names=factor(names(weightsorted), levels = factor(names(weightsorted))),
                       weights=weightsorted, 
                       signs=rbinded_signs_sorted)

weightdf_top <- weightdf[n:1,]
weightdf_top$names <- factor(weightdf_top$names, levels = weightdf_top$names)

g<- ggplot(weightdf_top, aes(x=weights, y=names, label=signs))+ 
  geom_point()+
  geom_segment(aes(x=0, xend=weights, y=names, yend=names))+
  geom_text(hjust=-1, size=5)+
  ggtitle(colnames(rbinded)[j])+
  labs(y="Variable names", x="Weights")+
  theme_bw()
  

print(g)
}
```





# Conclusions
We have identified a method analogous to that of `MOFA` that allows us
to combine different omics data without the need for prior imputation
of missing values. A major difference is that while `MOFA` model
learns "factors" that are composites of the variables in an
unsupervised fashion, the `plasma` model learns "components" that are
composites of the variables in an supervised fashion, using the
outcomes "event" and "time-to-event" as response variables.

Although the factors from `MOFA` are defined such that the efirst
factor, Factor 1, accounts for the greatest variance in the model, the
factors' may or may not be significantly associated with the outcome,
and a post-hoc survival analysis would need to be done to assess
this. It may be the case that some factors, although they are
significantly associated with outcome, account for very small variance
in the final `MOFA` model, which hinders interpretability. This was
the case with the TCGA-ESCA dataset, in which, when 10 factors were
learned from the `MOFA` model, only Factor 10 was significantly
associated with survival, while accounting for [number] variance in
the model [CITE SUPPLEMENTARY RESULTS?]. On the other hand, the
components for `plasma` are created in a way that maximizes the
covariance in the predictors and the response, and therefore these
components will be automatically associated to some degree with the
outcome. This could be advantageous in that dissecting the weights
associated with the components would yield a list of variables from
different omics datasets that contribute the most to defining the
outcome, and any additional analyses could be refined by looking at
these high-weighted variables most closely.

# Appendix: MOFA2

```{r mofa}
suppressWarnings( library(MOFA2) )
library(ggplot2)
library(dplyr)
library(tidyr)
```

In the final MOFA model, we would prefer that no single variable explains the most variance in the model simply because they encompass a wide range of values. For example, the untransformed "days_to_birth" column in "ClinicalCont" has a particularly wide range.

```{r}
range(assemble$ClinicalCont["days_to_birth",])
```

We will create a vector of names of datasets that are continuous (not binary) and scale them around 0 before running MOFA.

```{r}
# scale the columns that are not binary
notbinarydata<-c("ClinicalCont","Meth450","miRSeq","mRNASeq","RPPA")
UseMeScaled<- lapply(MO@data[notbinarydata], function(x) scale(x))
UseMeScaled$ClinicalBin <- MO@data$ClinicalBin
UseMeScaled$MAF <- MO@data$MAF
```

```{r}
oof <- create_mofa(UseMeScaled)
oof
plot_data_overview(oof)
```

First, we need to output the options and alter them if necessary. There are three, called "data options" "model options" and "training options".

```{r}
dataoptions <- get_default_data_options(oof)
dataoptions

modeloptions <- MOFA2::get_default_model_options(oof)
modeloptions$num_factors <-10

modeloptions

modeloptions[["likelihoods"]][["ClinicalBin"]] <- "bernoulli"
modeloptions[["likelihoods"]][["MAF"]] <- "bernoulli"

modeloptions

trainingoptions <- get_default_training_options(oof)
trainingoptions

oof <- prepare_mofa(oof, data_options = dataoptions, model_options = modeloptions, training_options = trainingoptions)
```

```{r}
# run MOFA if the file does not exist
if (file.exists("mofaESCAScaled.Rda")){
load("mofaESCAScaled.Rda") 
} else{
starttime<-Sys.time()
mofaESCAScaled <- run_mofa(oof, use_basilisk = TRUE)
save(mofaESCAScaled, file = "mofaESCAScaled.Rda")
endtime<-Sys.time()
endtime-starttime  
}
```

## Looking at the factors: 

plot_factor_cor

```{r, message= FALSE, warning= FALSE,  fig.height=9, fig.width=13}

# How do the factors correlate to each other? 

plot_factor_cor(mofaESCAScaled)

# Variance explained: 

plot_variance_explained(mofaESCAScaled, plot_total = T)[[2]]

plot_variance_explained(mofaESCAScaled)
```

## Heatmaps for the weight:

```{r, message=FALSE, warning=FALSE, fig.height=15, fig.width=15}

size <- sapply(UseMeScaled, dim)
type <- sapply(UseMeScaled, function(M) {
  U <- unique(as.vector(as.matrix(M)))
  ifelse (length(U) >3, "gaussian", "bernoulli")
})
heatme <- function() {
  Y <-  lapply(names(UseMeScaled), function(V) {
    sz <- size[1, V] < 200
    MOFA2::plot_weights_heatmap(mofaESCAScaled, view = V, main = V, show_colnames = sz, silent = TRUE)
  })
  Z <- lapply(Y, function(x) x$gtable)
  W <- gridExtra::arrangeGrob(Z[[1]], Z[[2]], Z[[3]], Z[[4]],
                              Z[[5]], Z[[6]], Z[[7]], nrow = 3)
  W
}
X <- heatme()
plot(X)

```


## Looking at each factor: 

```{r, message=FALSE, warning=FALSE, fig.width = 15, fig.height = 15 }
factorTopWeights <- function(J, mymofainput, mymofaoutput) {
  Z <-  lapply(names(mymofainput), function(V) {
    plot_top_weights(mymofaoutput, view = V, factor = J) + ggplot2::ggtitle(V)
  })
  W <- gridExtra::grid.arrange(Z[[1]], Z[[2]], Z[[3]], Z[[4]],
                               Z[[5]], Z[[6]], Z[[7]], 
                               nrow = 3)
}

factorTopWeights(J=1, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=2, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=3, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=4, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=5, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=6, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=7, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=8, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=9, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
factorTopWeights(J=10, mymofainput = UseMeScaled, mymofaoutput = mofaESCAScaled)
```


## Relationship to Overall Survival

```{r}
LF <- get_factors(mofaESCAScaled, groups = "all", factors = "all") [[1]]

all(rownames(MO@outcome) == rownames(LF))

vitalstatus2 <- ifelse(MO@outcome$vital_status=="alive", 0,
                       ifelse(MO@outcome$vital_status=="dead", 1, NA))
LFwithOutcome<- data.frame(LF, event =  vitalstatus2, time_to_event = MO@outcome$Days) 

```

```{r, warning=FALSE}
LF2 <- as.data.frame(t(LF))

OSresults <- matrix(NA, nrow=nrow(LF2), ncol = 4)
rownames(OSresults) <- rownames(LF2)
colnames(OSresults) <- c("coef", "HR", "score", "pvalue")


for (J in 1:nrow(LF2)) {
  tempdf <- data.frame(Time = LFwithOutcome$time_to_event,
                       Event = LFwithOutcome$event,
                       X <- LF2[J,])
  model <- coxph(Surv(Time, Event) ~ unlist(X), data = tempdf)
  S <- summary(model)
  val <- c(S$coefficients[1:2], S$sctest[c(1,3)])
  OSresults[J,] <- val}

OSresults
```

```{r, message=FALSE, warning=FALSE, results=FALSE}
osmodel <- survival::coxph(Surv(LFwithOutcome$time_to_event, LFwithOutcome$event) ~. , data = LFwithOutcome)
AIC <- stats::step(osmodel)

summary(osmodel)
summary(AIC)
```

Factor 10 is the only factor significantly associated with survival.


## Looking at Hazards ratio - OS: 

```{r}
s <- summary(osmodel)
coef <- s[["coefficients"]]

df <- data.frame(
  factor = factor(rownames(coef), levels = rev(rownames(coef))),
  p      = coef[,"Pr(>|z|)"], 
  coef   = coef[,"exp(coef)"], 
  lower  = s[["conf.int"]][,"lower .95"], 
  higher = s[["conf.int"]][,"upper .95"]
)

ggplot(df, aes(x=factor, y=coef, ymin=lower, ymax=higher)) +
  geom_pointrange( col='#619CFF') + 
  coord_flip() +
  scale_x_discrete() + 
  labs(y="Hazard Ratio", x="") + 
  geom_hline(aes(yintercept=1), linetype="dotted") +
  theme_bw()
```

The only factor significantly associated with survival outcome is Factor 10, which is marginal in terms of the variance explained in the model:

```{r}
library(tidyr)
v10<- plot_variance_explained(mofaESCAScaled)
v10wide<-pivot_wider(v10$data, names_from="factor", values_from="value")
v10wide<-v10wide %>% select(-c("group"))
v10wide<-as.data.frame(v10wide) 
rownames(v10wide) <- v10wide[,1]
v10wide<-v10wide[,-1]
v10wide_t<-t(v10wide)
sort(rowSums(v10wide_t), decreasing = TRUE)
```

The variances don not total to 100, so they are not really like what we normally think of when we say $R^2$. 
Possibly it would be easier to interpret if we force them into percentages like this:

```{r}
barplot(sort( rowSums(v10wide_t)/sum(rowSums(v10wide_t)) , decreasing = TRUE ), las=2, 
        main="Relative R^2")
sort( rowSums(v10wide_t)/sum(rowSums(v10wide_t)) , decreasing = TRUE )
```


## Some tentative conclusions from MOFA

* This may highlight a crucial problem in MOFA, in which Factors that have a large variance explained in the model (usually the first few factors) may not be significantly related to survival outcome when doing the post-hoc analysis.

* This is because these factors were learned with respect to explaining the most variance within the model, without any supervision. There is some "luck" associated with finding Factors that contribute to defining the model and are also significantly related to outcome.

* Plasma solves this problem of the Factors becoming dissociated with outcome, since plasma is a supervised analysis that purposefully learns components that explain the outcome.


